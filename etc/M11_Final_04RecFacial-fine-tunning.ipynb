{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **`04 FINE TUNNING`**\n","\n","Cuando un nuevo persona ingrese, sera necesario añadir al modelo esos nuevos personas, para no entrenar otra vez todo, se le añade nuevas capas"],"metadata":{"id":"zehNKu367ryt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"to8JGNoy7kTG"},"outputs":[],"source":["import numpy as np\n","import os\n","import cv2\n","import json\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","source":["# Configuración\n","IMG_SIZE = 64\n","BATCH_SIZE = 32\n","EPOCHS = 20\n","LEARNING_RATE = 0.0001  # Tasa de aprendizaje más baja"],"metadata":{"id":"_Au0HzXR8XOu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Función para cargar imágenes y etiquetas\n","def load_data(dir_path):\n","    images = []\n","    labels = []\n","    for person_name in os.listdir(dir_path):\n","        person_path = os.path.join(dir_path, person_name)\n","        if os.path.isdir(person_path):\n","            for img_name in os.listdir(person_path):\n","                img_path = os.path.join(person_path, img_name)\n","                img = cv2.imread(img_path)\n","                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n","                img = img[:, :, ::-1] / 255.0  # BGR to RGB and normalize\n","                images.append(img)\n","                labels.append(person_name)\n","    return np.array(images), np.array(labels)"],"metadata":{"id":"HJXlBPGw8bNY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","# Montar Google Drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPkdXOsZ8lGi","outputId":"5b33230e-255f-425a-c839-3f2d849caf52","executionInfo":{"status":"ok","timestamp":1722710407834,"user_tz":240,"elapsed":20654,"user":{"displayName":"Marcelo Condori","userId":"18399826197065823050"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Cargar el modelo existente\n","# model = load_model('/content/drive/MyDrive/Personales/Estudio/BigData/Mod11/TareaFinal/face_recognition_model.h5')\n","model = load_model('/content/drive/MyDrive/ProyectoFotos/Modelo/face_recognition_model.h5')\n","\n","# Cargar las etiquetas existentes\n","# with open('/content/drive/MyDrive/Personales/Estudio/BigData/Mod11/TareaFinal/face_recognition_model.json', 'r') as f:\n","with open('/content/drive/MyDrive/ProyectoFotos/JSON/face_recognition_model.json', 'r') as f:\n","    existing_labels = json.load(f)"],"metadata":{"id":"Kh-92Snv9Tfg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722710533901,"user_tz":240,"elapsed":1158,"user":{"displayName":"Marcelo Condori","userId":"18399826197065823050"}},"outputId":"94949f0a-8dac-4fa5-fe83-c9c72aed7a73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]}]},{"cell_type":"code","source":["# Cargar una parte de los datos originales (ajusta la ruta según sea necesario)\n","# original_dir_path = '/content/drive/MyDrive/Personales/Estudio/BigData/Mod11/TareaFinal/personas_224x224'\n","original_dir_path = '/content/drive/MyDrive/ProyectoFotos/Celebrity_Faces_Dataset/personas_nuevas_224x224'\n","original_images, original_labels = load_data(original_dir_path)"],"metadata":{"id":"NdD0uW5MPNPU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cargar nuevos datos\n","# new_dir_path = '/content/drive/MyDrive/Personales/Estudio/BigData/Mod11/TareaFinal/personas_nuevas_224x224'\n","new_dir_path = '/content/drive/MyDrive/ProyectoFotos/Celebrity_Faces_Dataset/personas_nuevas_224x224'\n","new_images, new_labels = load_data(new_dir_path)"],"metadata":{"id":"II4VyzO79WD-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Combinar datos originales y nuevos\n","all_images = np.concatenate([original_images, new_images])\n","all_labels = np.concatenate([original_labels, new_labels])"],"metadata":{"id":"kTYXAutIPCP8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Actualizar el mapeo de etiquetas\n","all_unique_labels = list(set(list(existing_labels.keys()) + list(np.unique(all_labels))))\n","le = LabelEncoder()\n","le.fit(all_unique_labels)\n","label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))"],"metadata":{"id":"gNcB7R_-PCKc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Codificar todas las etiquetas\n","all_labels_encoded = le.transform(all_labels)\n","all_labels_one_hot = to_categorical(all_labels_encoded, num_classes=len(label_mapping))"],"metadata":{"id":"UuEtzMOTPCEN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modificar la capa de salida del modelo\n","model.pop()  # Eliminar la última capa\n","for layer in model.layers[:-2]:  # Congelar todas las capas excepto las dos últimas\n","    layer.trainable = False\n","new_output_layer = Dense(len(label_mapping), activation='softmax')\n","model.add(new_output_layer)"],"metadata":{"id":"mF8L1OiHPUWt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compilar el modelo actualizado con una tasa de aprendizaje más baja\n","optimizer = Adam(learning_rate=LEARNING_RATE)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"],"metadata":{"id":"B7hw-bRuPURg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fine-tuning\n","history = model.fit(all_images, all_labels_one_hot, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-H--u2DSPaew","outputId":"05551677-cfb0-4cac-9d55-a97677aa20ab","executionInfo":{"status":"ok","timestamp":1722711264654,"user_tz":240,"elapsed":166270,"user":{"displayName":"Marcelo Condori","userId":"18399826197065823050"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - accuracy: 0.1938 - loss: 2.6296 - val_accuracy: 0.1514 - val_loss: 2.4153\n","Epoch 2/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - accuracy: 0.5602 - loss: 1.5674 - val_accuracy: 0.4159 - val_loss: 1.8029\n","Epoch 3/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.6897 - loss: 1.2074 - val_accuracy: 0.5856 - val_loss: 1.4270\n","Epoch 4/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 80ms/step - accuracy: 0.7845 - loss: 0.9696 - val_accuracy: 0.6774 - val_loss: 1.1979\n","Epoch 5/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - accuracy: 0.8219 - loss: 0.8234 - val_accuracy: 0.6896 - val_loss: 1.1339\n","Epoch 6/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.8543 - loss: 0.6917 - val_accuracy: 0.7584 - val_loss: 0.9596\n","Epoch 7/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - accuracy: 0.8877 - loss: 0.5917 - val_accuracy: 0.7783 - val_loss: 0.8901\n","Epoch 8/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - accuracy: 0.9084 - loss: 0.5318 - val_accuracy: 0.8119 - val_loss: 0.7684\n","Epoch 9/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.9205 - loss: 0.4875 - val_accuracy: 0.7997 - val_loss: 0.7663\n","Epoch 10/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.9425 - loss: 0.4238 - val_accuracy: 0.8440 - val_loss: 0.6591\n","Epoch 11/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 96ms/step - accuracy: 0.9510 - loss: 0.3768 - val_accuracy: 0.8670 - val_loss: 0.6225\n","Epoch 12/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.9478 - loss: 0.3553 - val_accuracy: 0.8609 - val_loss: 0.5907\n","Epoch 13/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 82ms/step - accuracy: 0.9570 - loss: 0.3243 - val_accuracy: 0.8899 - val_loss: 0.5227\n","Epoch 14/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.9653 - loss: 0.2966 - val_accuracy: 0.9128 - val_loss: 0.4539\n","Epoch 15/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.9714 - loss: 0.2757 - val_accuracy: 0.9235 - val_loss: 0.4295\n","Epoch 16/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.9681 - loss: 0.2618 - val_accuracy: 0.9327 - val_loss: 0.4008\n","Epoch 17/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.9802 - loss: 0.2298 - val_accuracy: 0.9495 - val_loss: 0.3460\n","Epoch 18/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.9846 - loss: 0.2085 - val_accuracy: 0.9618 - val_loss: 0.3117\n","Epoch 19/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 95ms/step - accuracy: 0.9811 - loss: 0.2020 - val_accuracy: 0.9572 - val_loss: 0.3206\n","Epoch 20/20\n","\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.9875 - loss: 0.1797 - val_accuracy: 0.9709 - val_loss: 0.2806\n"]}]},{"cell_type":"code","source":["def save_labels(labels, filename):\n","    labels = {k: int(v) for k, v in labels.items()}\n","    with open(filename, 'w') as f:\n","        json.dump(labels, f)"],"metadata":{"id":"lQHBHR51Pabw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Guardar el modelo y las etiquetas actualizadas\n","# model.save('/content/drive/MyDrive/Personales/Estudio/BigData/Mod11/TareaFinal/face_recognition_model_updated.h5')\n","model.save('/content/drive/MyDrive/ProyectoFotos/Modelo/face_recognition_model_updated.h5')\n","\n","def save_labels(labels, filename):\n","    labels = {k: int(v) for k, v in labels.items()}\n","    with open(filename, 'w') as f:\n","        json.dump(labels, f)\n","\n","# save_labels(label_mapping, '/content/drive/MyDrive/Personales/Estudio/BigData/Mod11/TareaFinal/face_recognition_model_updated.json')\n","save_labels(label_mapping, '/content/drive/MyDrive/ProyectoFotos/JSON/face_recognition_model_updated.json')\n","\n","print(\"Modelo y etiquetas actualizados guardados exitosamente.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XKmwVwT6PaZH","outputId":"1fa852ae-6c20-4059-86ef-c9b12ebdc55f","executionInfo":{"status":"ok","timestamp":1722711566108,"user_tz":240,"elapsed":340,"user":{"displayName":"Marcelo Condori","userId":"18399826197065823050"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Modelo y etiquetas actualizados guardados exitosamente.\n"]}]}]}